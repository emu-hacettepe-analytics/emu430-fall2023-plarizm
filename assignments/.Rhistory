SD_PM10 = sd(pm10_values, na.rm = TRUE),
Average_Forest_Area = mean(forest_area, na.rm = TRUE),
SD_Forest_Area = sd(forest_area, na.rm = TRUE)
)
# Histogram of PM10 Values
p1 <- ggplot(project_data, aes(x = pm10_values)) +
geom_histogram(binwidth = 5, fill = "blue", color = "black") +
theme_minimal() +
labs(title = "Histogram of PM10 Values",
x = "PM10 Values", y = "Frequency")
# Histogram of Forest Area
p2 <- ggplot(project_data, aes(x = forest_area)) +
geom_histogram(binwidth = 5, fill = "green", color = "black") +
theme_minimal() +
labs(title = "Histogram of Forest Area",
x = "Forest Area", y = "Frequency")
# Scatter Plot with Regression Line
p3 <- ggplot(project_data, aes(x = pm10_values, y = forest_area)) +
geom_point(color = "red") +
labs(title = "Scatter Plot of PM10 Values vs Forest Area",
x = "PM10 Values", y = "Forest Area")
grid.arrange(p1, p2, p3, nrow = 3)
p3
# Libraries
library(ggplot2)
library(dplyr)
library(gridExtra)
# Summary
summary_data <- project_data %>% summarise(
Average_PM10 = mean(pm10_values),
SD_PM10 = sd(pm10_values),
Average_Forest_Area = mean(forest_area),
SD_Forest_Area = sd(forest_area)
)
# Histogram of PM10 Values
p1 <- ggplot(project_data, aes(x = pm10_values)) +
geom_histogram(binwidth = 5, fill = "blue", color = "black") +
theme_minimal() +
labs(title = "Histogram of PM10 Values",
x = "PM10 Values", y = "Frequency")
# Histogram of Forest Area
p2 <- ggplot(project_data, aes(x = forest_area)) +
geom_histogram(binwidth = 5, fill = "green", color = "black") +
theme_minimal() +
labs(title = "Histogram of Forest Area",
x = "Forest Area", y = "Frequency")
# Scatter Plot with Regression Line
p3 <- ggplot(project_data, aes(x = pm10_values, y = forest_area)) +
geom_point(color = "red") +
labs(title = "Scatter Plot of PM10 Values vs Forest Area",
x = "PM10 Values", y = "Forest Area")
p3
# Libraries
library(ggplot2)
library(dplyr)
library(gridExtra)
# Summary
summary_data <- project_data %>% summarise(
Average_PM10 = mean(pm10_values),
SD_PM10 = sd(pm10_values),
Average_Forest_Area = mean(forest_area),
SD_Forest_Area = sd(forest_area)
)
# Histogram of PM10 Values
p1 <- ggplot(project_data, aes(x = pm10_values)) +
geom_histogram(binwidth = 5, fill = "blue", color = "black") +
theme_minimal() +
labs(title = "Histogram of PM10 Values",
x = "PM10 Values", y = "Frequency")
# Histogram of Forest Area
p2 <- ggplot(project_data, aes(x = forest_area)) +
geom_histogram(binwidth = 5, fill = "green", color = "black") +
theme_minimal() +
labs(title = "Histogram of Forest Area",
x = "Forest Area", y = "Frequency")
# Scatter Plot with Regression Line
p3 <- ggplot(project_data, aes(x = pm10_values, y = forest_area)) +
geom_point(color = "red") +
labs(title = "Scatter Plot of PM10 Values vs Forest Area",
x = "PM10 Values", y = "Forest Area")
p1,p2,p3
# Libraries
library(ggplot2)
library(dplyr)
library(gridExtra)
# Summary
summary_data <- project_data %>% summarise(
Average_PM10 = mean(pm10_values),
SD_PM10 = sd(pm10_values),
Average_Forest_Area = mean(forest_area),
SD_Forest_Area = sd(forest_area)
)
# Histogram of PM10 Values
p1 <- ggplot(project_data, aes(x = pm10_values)) +
geom_histogram(binwidth = 5, fill = "blue", color = "black") +
theme_minimal() +
labs(title = "Histogram of PM10 Values",
x = "PM10 Values", y = "Frequency")
# Histogram of Forest Area
p2 <- ggplot(project_data, aes(x = forest_area)) +
geom_histogram(binwidth = 5, fill = "green", color = "black") +
theme_minimal() +
labs(title = "Histogram of Forest Area",
x = "Forest Area", y = "Frequency")
# Scatter Plot with Regression Line
p3 <- ggplot(project_data, aes(x = pm10_values, y = forest_area)) +
geom_point(color = "red") +
labs(title = "Scatter Plot of PM10 Values vs Forest Area",
x = "PM10 Values", y = "Forest Area")
p1
p2
p3
# Libraries
library(ggplot2)
library(dplyr)
# Summary
summary_data <- project_data %>% summarise(
Average_PM10 = mean(pm10_values),
SD_PM10 = sd(pm10_values),
Average_Forest_Area = mean(forest_area),
SD_Forest_Area = sd(forest_area)
)
# Histogram Plot of PM10 Values
p1 <- ggplot(project_data, aes(x = pm10_values)) +
geom_histogram(binwidth = 5, fill = "blue", color = "black") +
theme_minimal() +
labs(title = "Histogram of PM10 Values",
x = "PM10 Values", y = "Frequency")
# Histogram of Forest Area
p2 <- ggplot(project_data, aes(x = forest_area)) +
geom_histogram(binwidth = 5, fill = "green", color = "black") +
theme_minimal() +
labs(title = "Histogram of Forest Area",
x = "Forest Area", y = "Frequency")
# Scatter Plot with Regression Line
p3 <- ggplot(project_data, aes(x = pm10_values, y = forest_area)) +
geom_point(color = "red") +
labs(title = "Scatter Plot of PM10 Values Compared with Forest Area",
x = "PM10 Values", y = "Forest Area")
p1
p2
p3
# Libraries
library(ggplot2)
library(dplyr)
# Summary
summary_data <- project_data %>% summarise(
Average_PM10 = mean(pm10_values),
SD_PM10 = sd(pm10_values),
Average_Forest_Area = mean(forest_area),
SD_Forest_Area = sd(forest_area)
)
# Histogram Plot of PM10 Values
p1 <- ggplot(project_data, aes(x = pm10_values)) +
geom_histogram(binwidth = 5, fill = "blue", color = "black") +
theme_minimal() +
labs(title = "Histogram of PM10 Values",
x = "PM10 Values", y = "Frequency")
# Histogram of Forest Area
p2 <- ggplot(project_data, aes(x = forest_area)) +
geom_histogram(binwidth = 5, fill = "green", color = "black") +
theme_minimal() +
labs(title = "Histogram of Forest Area",
x = "Forest Area", y = "Frequency")
# Scatter Plot with Regression Line
p3 <- ggplot(project_data, aes(x = pm10_values, y = forest_area)) +
geom_point(color = "red") +
labs(title = "Scatter Plot of PM10 Values Compared with Forest Area",
x = "PM10 Values", y = "Forest Area")
multiplot(p1,p2,p3)
library(tidyverse) # for everything :)
library(rvest) # for HTML scraping
library(stringr) # for string processing
data_urls <- c('https://www.imdb.com/search/title/?title_type=feature&release_date=,2009-12-31&sort=release_date,desc&num_votes=2500,&country_of_origin=TR&count=250','https://m.imdb.com/search/title/?title_type=feature&release_date=2010-01-01,2023-12-31&sort=release_date,desc&num_votes=2500,&country_of_origin=TR&count=250')
data_html <- c()
for (x in data_urls) {
a <- read_html(x)
data_html <- c(data_html, list(a))
}
titles_list <- c()
for (doc in data_html) {
title_elements <- html_elements(doc, '.ipc-title__text') %>% html_text()
titles_list <- c(titles_list, title_elements)
}
titles_list <- titles_list[!grepl("Advanced", titles_list)]
titles_list <- titles_list[!grepl("Recently", titles_list)]
titles_cleaned <- c()
for (x in titles_list) {
a <- gsub("^[0-9]+\\.\\s*", "", x)
titles_cleaned <- c(titles_cleaned, a)
}
title_metadata_list <- c()
for (num in data_html) {
year_elements <- html_elements(num, '.sc-43986a27-8.jHYIIK.dli-title-metadata-item') %>% html_text()
title_metadata_list <- c(title_metadata_list, year_elements)
}
years_cleaned <- c()
for (a in title_metadata_list) {
x <- grep("^[0-9]+$", a, value = TRUE)
years_cleaned <- c(years_cleaned, x)
}
years_cleaned <- as.integer(years_cleaned)
duration_elements <- c()
for (a in title_metadata_list) {
x <- grep("[hm]", a, value = TRUE)
duration_elements <- c(duration_elements, x)
}
convert_to_minutes <- function(time_str) {
hours <- as.numeric(str_extract(time_str, "\\d+(?=h)"))
minutes <- as.numeric(str_extract(time_str, "\\d+(?=m)"))
if (is.na(hours)) { hours <- 0 }
if (is.na(minutes)) { minutes <- 0 }
total_minutes <- hours * 60 + minutes
return(total_minutes)
}
durations_cleaned <- c()
for (a in duration_elements){
x <- convert_to_minutes(a)
durations_cleaned <- c(durations_cleaned, x)
}
rating_vote_data <- c()
for (page in data_html) {
data <- html_elements(page, '.ipc-rating-star.ipc-rating-star--base.ipc-rating-star--imdb.ratingGroup--imdb-rating') %>%
html_text(trim = TRUE)
rating_vote_data <- c(rating_vote_data, data)
}
ratings_list <- c()
for (data in rating_vote_data) {
year_elements_2 <- sub("^([0-9]\\.[0-9]).*$", "\\1", data)
ratings_list <- c(ratings_list, year_elements_2)
}
ratings_cleaned <- as.numeric(ratings_list)
vote_list <- c()
for (num in data_html) {
vote <- html_elements(num, '.sc-53c98e73-0.kRnqtn') %>% html_text()
vote_list <- c(vote_list, vote)
}
votes_cleaned <- as.numeric(sapply(vote_list, function(x) {
numeric_value <- gsub("Votes|,", "", x)
}))
scrapped_data <- data.frame(Title = titles_cleaned, Year = years_cleaned, Duration = durations_cleaned, Rating = ratings_cleaned, Vote = votes_cleaned)
descending_by_rating <- scrapped_data[order(scrapped_data$Rating, decreasing = TRUE),]
top_five <- slice_head(descending_by_rating, n=5)
bottom_five <- slice_tail(descending_by_rating, n=5)
replace_turkish_chars <- function(text) {
replacements <- c("??" = "c", "??" = "g", "??" = "i", "??" = "o", "??" = "s", "??" = "u",
"??" = "C", "??" = "G", "??" = "I", "??" = "O", "??" = "S", "??" = "U")
for (char in names(replacements)) {
text <- str_replace_all(text, char, replacements[char])
}
return(text)
}
scrapped_data$Title <- sapply(scrapped_data$Title, replace_turkish_chars)
replace_turkish_chars <- function(text) {
replacements <- c("ç" = "c", "ğ" = "g", "ı" = "i", "ö" = "o", "ş" = "s", "ü" = "u",
replace_turkish_chars <- function(text) {
replacements <- c("ç" = "c", "ğ" = "g", "ı" = "i", "ö" = "o", "ş" = "s", "ü" = "u",
replace_turkish_chars <- function(text) {
replacements <- c("ç" = "c", "ğ" = "g", "ı" = "i", "ö" = "o", "ş" = "s", "ü" = "u",
View(descending_by_rating)
new_metadata_list <- new_data_html %>% html_elements(".sc-43986a27-8.jHYIIK.dli-title-metadata-item") %>% html_text()
library(tidyverse) # for everything :)
library(rvest) # for HTML scraping
library(stringr) # for string processing
library(scales) #for formatting
library(tidyverse) # for everything :)
library(rvest) # for HTML scraping
library(stringr) # for string processing
library(scales) #for formatting
new_metadata_list <- new_data_html %>% html_elements(".sc-43986a27-8.jHYIIK.dli-title-metadata-item") %>% html_text()
new_data_url <- "https://m.imdb.com/search/title/?title_type=feature&groups=top_1000&country_of_origin=TR"
new_data_html <- read_html(new_data_url)
new_titles <- new_data_html %>% html_elements(".ipc-title__text") %>% html_text()
new_titles <- new_titles[!grepl("Advanced", new_titles)]
new_titles <- new_titles[!grepl("Recently", new_titles)]
new_titles_cleaned <- c()
for (x in new_titles) {
a <- gsub("^[0-9]+\\.\\s*", "", x)
new_titles_cleaned <- c(new_titles_cleaned, a)
}
new_data_url <- "https://m.imdb.com/search/title/?title_type=feature&groups=top_1000&country_of_origin=TR"
new_data_html <- read_html(new_data_url)
new_titles <- new_data_html %>% html_elements(".ipc-title__text") %>% html_text()
new_titles <- new_titles[!grepl("Advanced", new_titles)]
new_titles <- new_titles[!grepl("Recently", new_titles)]
new_titles_cleaned <- c()
for (x in new_titles) {
a <- gsub("^[0-9]+\\.\\s*", "", x)
new_titles_cleaned <- c(new_titles_cleaned, a)
}
new_metadata_list <- new_data_html %>% html_elements(".sc-43986a27-8.jHYIIK.dli-title-metadata-item") %>% html_text()
new_years_cleaned <- c()
for (a in new_metadata_list) {
x <- grep("^[0-9]+$", a, value = TRUE)
new_years_cleaned <- c(new_years_cleaned, x)
}
new_years_cleaned <- as.integer(new_years_cleaned)
new_data <- data.frame(Title = new_titles_cleaned, Year = new_years_cleaned)
joined_data <- new_data %>% left_join(scrapped_data, by = c("Title", "Year"))
new_descending_by_rating <- joined_data[order(joined_data$Rating, decreasing = TRUE),]
View(joined_data)
View(descending_by_rating)
View(new_descending_by_rating)
first_11_old <- head(descending_by_rating, n=11)
first_11_new <- new_descending_by_rating
first_11_old <- head(descending_by_rating, n=11)
first_11_new <- new_descending_by_rating
identical(first_11_old, first_11_new)
View(first_11_new)
View(first_11_old)
setwd("C:/Users/serha/Documents/emu430-fall2023-plarizm/assignments")
first_11_old <- head(descending_by_rating, n=11)
first_11_new <- new_descending_by_rating
View(first_11_old)
View(first_11_new)
identical(first_11_old, first_11_new)
first_11_old <- head(descending_by_rating, n=11)
first_11_new <- new_descending_by_rating
knitr::kable(first_11_old)
knitr::kable(first_11_new)
identical(first_11_old, first_11_new)
first_11_old <- head(descending_by_rating, n=11)
first_11_new <- new_descending_by_rating
knitr::kable(first_11_old)
knitr::kable(first_11_new)
identical(first_11_old, first_11_new)
first_11_old <- head(descending_by_rating, n=11)
first_11_new <- new_descending_by_rating
grid.arrange(tableGrob(first_11_old), tableGrob(first_11_new), ncol = 2)
library(tidyverse) # for everything :)
library(rvest) # for HTML scraping
library(stringr) # for string processing
library(scales) #for formatting
library(gridExtra) #for showing data
library(tidyverse) # for everything :)
library(rvest) # for HTML scraping
library(stringr) # for string processing
library(scales) #for formatting
library(gridExtra) #for showing data
first_11_old <- head(descending_by_rating, n=11)
first_11_new <- new_descending_by_rating
grid.arrange(tableGrob(first_11_old), tableGrob(first_11_new), ncol = 2)
identical(first_11_old, first_11_new)
first_11_old <- head(descending_by_rating, n=11)
first_11_new <- new_descending_by_rating
knitr::kable(first_11_old)
knitr::kable(first_11_new)
identical(first_11_old, first_11_new)
library(tidyverse) # for everything :)
library(rvest) # for HTML scraping
library(stringr) # for string processing
library(scales) #for formatting
library(gridExtra) #for showing data
library(tidyverse) # for everything :)
library(rvest) # for HTML scraping
library(stringr) # for string processing
data_urls <- c('https://www.imdb.com/search/title/?title_type=feature&release_date=,2009-12-31&sort=release_date,desc&num_votes=2500,&country_of_origin=TR&count=250','https://m.imdb.com/search/title/?title_type=feature&release_date=2010-01-01,2023-12-31&sort=release_date,desc&num_votes=2500,&country_of_origin=TR&count=250')
data_html <- c()
for (x in data_urls) {
a <- read_html(x)
data_html <- c(data_html, list(a))
}
titles_list <- c()
for (doc in data_html) {
title_elements <- html_elements(doc, '.ipc-title__text') %>% html_text()
titles_list <- c(titles_list, title_elements)
}
titles_list <- titles_list[!grepl("Advanced", titles_list)]
titles_list <- titles_list[!grepl("Recently", titles_list)]
titles_cleaned <- c()
for (x in titles_list) {
a <- gsub("^[0-9]+\\.\\s*", "", x)
titles_cleaned <- c(titles_cleaned, a)
}
title_metadata_list <- c()
for (num in data_html) {
year_elements <- html_elements(num, '.sc-43986a27-8.jHYIIK.dli-title-metadata-item') %>% html_text()
title_metadata_list <- c(title_metadata_list, year_elements)
}
years_cleaned <- c()
for (a in title_metadata_list) {
x <- grep("^[0-9]+$", a, value = TRUE)
years_cleaned <- c(years_cleaned, x)
}
years_cleaned <- as.integer(years_cleaned)
duration_elements <- c()
for (a in title_metadata_list) {
x <- grep("[hm]", a, value = TRUE)
duration_elements <- c(duration_elements, x)
}
convert_to_minutes <- function(time_str) {
hours <- as.numeric(str_extract(time_str, "\\d+(?=h)"))
minutes <- as.numeric(str_extract(time_str, "\\d+(?=m)"))
if (is.na(hours)) { hours <- 0 }
if (is.na(minutes)) { minutes <- 0 }
total_minutes <- hours * 60 + minutes
return(total_minutes)
}
durations_cleaned <- c()
for (a in duration_elements){
x <- convert_to_minutes(a)
durations_cleaned <- c(durations_cleaned, x)
}
rating_vote_data <- c()
for (page in data_html) {
data <- html_elements(page, '.ipc-rating-star.ipc-rating-star--base.ipc-rating-star--imdb.ratingGroup--imdb-rating') %>%
html_text(trim = TRUE)
rating_vote_data <- c(rating_vote_data, data)
}
ratings_list <- c()
for (data in rating_vote_data) {
rating_elements <- sub("^([0-9]\\.[0-9]).*$", "\\1", data)
ratings_list <- c(ratings_list, rating_elements)
}
ratings_cleaned <- as.numeric(ratings_list)
vote_list <- c()
for (num in data_html) {
vote <- html_elements(num, '.sc-53c98e73-0.kRnqtn') %>% html_text()
vote_list <- c(vote_list, vote)
}
votes_cleaned <- as.numeric(sapply(vote_list, function(x) {
numeric_value <- gsub("Votes|,", "", x)
}))
scrapped_data <- data.frame(Title = titles_cleaned, Year = years_cleaned, Duration = durations_cleaned, Rating = ratings_cleaned, Vote = votes_cleaned)
descending_by_rating <- scrapped_data[order(scrapped_data$Rating, decreasing = TRUE),]
top_five <- slice_head(descending_by_rating, n=5)
bottom_five <- slice_tail(descending_by_rating, n=5)
# you should write this code to local console to process turkish characters without any problem:
#Sys.setlocale(category = "LC_ALL", locale = "Turkish")
my_favorites <- filter(scrapped_data, Title %in% c("G.O.R.A.","Ölümlü Dünya 2","Organize Isler"))
my_favorites %>% select(Title, Rating)
yearly_average <- scrapped_data %>% group_by(Year) %>% summarise(AverageRating = mean(Rating))
# Number of movies over the years
movies_per_year <- scrapped_data %>% group_by(Year) %>% summarise(NumberOfMovies = n())
ggplot(movies_per_year, aes(x = Year, y = NumberOfMovies)) +
geom_point() +
theme_minimal() +
labs(title = "Number of Turkish Movies Released Each Year",
x = "Year",
y = "Number of Movies")
# Yearly rating averages
ggplot(yearly_average, aes(x = Year, y = AverageRating)) +
geom_point() +
theme_minimal() +
labs(title = "Yearly Average Ratings of Turkish Movies",
x = "Year",
y = "Average Rating")
# box plots of ratings over the years
ggplot(scrapped_data, aes(x = as.factor(Year), y = Rating)) +
geom_boxplot() +
theme_minimal() +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
labs(title = "Box Plot of Movie Ratings Over the Years",
x = "Year",
y = "Rating")
ggplot(scrapped_data, aes(x = Vote, y = Rating)) +
geom_point(alpha = 0.5) +
geom_smooth(method = "lm", color = "red") +
scale_x_log10(labels = scales::label_number_auto()) +
theme_minimal() +
labs(title = "Correlation Between Votes and Ratings",
x = "Number of Votes",
y = "Rating")
ggplot(scrapped_data, aes(x = Duration, y = Rating)) +
geom_point(alpha = 0.5) +
geom_smooth(method = "lm", color = "blue") +
scale_x_log10() +
theme_minimal() +
labs(title = "Relationship Between Movie Duration and Rating",
x = "Duration (minutes)",
y = "Rating")
new_data_url <- "https://m.imdb.com/search/title/?title_type=feature&groups=top_1000&country_of_origin=TR"
new_data_html <- read_html(new_data_url)
new_titles <- new_data_html %>% html_elements(".ipc-title__text") %>% html_text()
new_titles <- new_titles[!grepl("Advanced", new_titles)]
new_titles <- new_titles[!grepl("Recently", new_titles)]
new_titles_cleaned <- c()
for (x in new_titles) {
a <- gsub("^[0-9]+\\.\\s*", "", x)
new_titles_cleaned <- c(new_titles_cleaned, a)
}
new_metadata_list <- new_data_html %>% html_elements(".sc-43986a27-8.jHYIIK.dli-title-metadata-item") %>% html_text()
new_years_cleaned <- c()
for (a in new_metadata_list) {
x <- grep("^[0-9]+$", a, value = TRUE)
new_years_cleaned <- c(new_years_cleaned, x)
}
new_years_cleaned <- as.integer(new_years_cleaned)
new_data <- data.frame(Title = new_titles_cleaned, Year = new_years_cleaned)
joined_data <- new_data %>% left_join(scrapped_data, by = c("Title", "Year"))
new_descending_by_rating <- joined_data[order(joined_data$Rating, decreasing = TRUE)]
library(tidyverse) # for everything :)
library(rvest) # for HTML scraping
library(stringr) # for string processing
data_urls <- c('https://www.imdb.com/search/title/?title_type=feature&release_date=,2009-12-31&sort=release_date,desc&num_votes=2500,&country_of_origin=TR&count=250','https://m.imdb.com/search/title/?title_type=feature&release_date=2010-01-01,2023-12-31&sort=release_date,desc&num_votes=2500,&country_of_origin=TR&count=250')
data_html <- c()
for (x in data_urls) {
a <- read_html(x)
data_html <- c(data_html, list(a))
}
new_descending_by_rating <- joined_data[order(joined_data$Rating, decreasing = TRUE),]
joined_data <- new_data %>% left_join(scrapped_data, by = c("Title", "Year"))
joined_data
View(joined_data)
joined_data
View(joined_data)
joined_data <- new_data %>% left_join(scrapped_data, by = c("Title", "Year"))
joined_data
joined_data <- new_data %>% left_join(scrapped_data, by = c("Title", "Year"))
heady(joined_data)
joined_data <- new_data %>% left_join(scrapped_data, by = c("Title", "Year"))
head(joined_data)
